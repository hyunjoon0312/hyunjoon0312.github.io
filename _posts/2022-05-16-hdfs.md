---
title:  "[HADOOP #1] HDFS란 무엇인가?"
excerpt: "HDFS를 구성하고 있는 Role과 HDFS의 기능에 대한 설명"
toc: true
toc_sticky: true
toc_label: "목차"

categories:
  - OSS
tags:
  - Hadoop
---

지난 포스팅에서 하둡 에코 시스템(Hadoop Eco System)이 어떤 서비스들로 이루어져 있는지와 어떤 기능을 가지고 있는지에 대해 정말 간략하게 알아보았습니다. 그리고 사전에 이야기 했듯이 이번 포스팅부터는 각 서비스에 대한 개념부터 설치 방법까지 알아보는 Deep Dive한 내용의 포스팅을 시작해보겠습니다.  



[관련글 – 하둡 에코 시스템(Hadoop Eco System)이란?](https://onestep-log.com/hadoop/hadoop-eco/)



그 시작으로는 역시 하둡 에코 시스템의 코어인 HDFS 입니다.

## HDFS란?

HDFS는 Hadoop Distributed File System(하둡 분산 파일 시스템)의 약어 입니다. 특징으로는 일반적인 하드웨어로 구성된 클러스터에서 실행되며 대용량 파일을 다룰 수 있도록 설계된 파일 시스템 입니다. 좀 더 상세한 특징은 아래와 같습니다.  

- 아주 큰 용량의 데이터 저장 가능 : 여기서 아주 큰 용량의 데이터는 작게는 수백 메가바이트부터 크게는 수십 페타바이트 크기의 데이터를 이야기 합니다. 단일 장비가 아닌 클러스터에 분산 저장을 하기 때문에 클러스터 규모에 따라 수용 가능한 데이터의 크기가 달라지게 됩니다.

- 스트리밍 방식의 데이터 이용 : 한번의 쓰기 작업 이후에 여러 번 읽는 것이 가장 효율적이 데이터 이용 방식이라는 컨셉을 가지고 있기 때문에 HDFS로 저장된 데이터는 수정이 불가능한 특징을 가지고 있습니다. 데이터를 수정하고 싶다면 현재의 데이터를 삭제 후 수정된 데이터를 다시 저장해야 합니다.(단, 마지막 데이터에 추가로 데이터를 이어서 붙이는 것은 가능합니다.)

- 일반적인 하드웨어 사용 : 하둡 에코 시스템을 구성하기 위한 하드웨어는 특별한 성능이나 안정성이 요구 되지 않습니다. 물론 쾌적하게 사용하기 위한 권장 사항은 있습니다. 그러나 하둡은 높은 내고장성(Fault Tolerance)을 보장하기 때문에 일반적인 하드웨어를 사용하여도 데이터 유실에 대한 가능성이 매우 적기 때문에 반드시 뛰어난 안정성을 가진 하드웨어가 필요하지 않습니다. 

-  파일 블록으로 저장 : 블록이라는 단위의 수 많은 파일들로 데이터가 저장 됩니다. 일반적인 블록의 크기는 128MB이며 좀 더 큰 용량의 데이터를 저장하는 경우에는 256MB의 블록 크기를 사용하기도 합니다



## 블록과 Replication Factor

HDFS는 블록이라는 개념을 가지고 있으며 데이터를 블록 단위로 쪼개서 저장합니다. 기본적인 블록의 크기는 128MB 이며, 저장하는 데이터의 크기가 큰 경우에는 많은 블록 생성되어 탐색 시간이 증가하는 것을 방지하기 위해 256MB로 설정하기도 합니다. 저장할 파일(데이터)의 크기가 블록 크기 보다 작을 경우에는 블록 크기만큼 무조건 디스크를 차지하는 것이 아니라 저장된 파일 만큼만 디스크가 사용됩니다. 따라서 블록 크기로 인해 디스크 공간이 불필요하게 버려지는 경우는 없습니다. 블록이라는 개념을 사용하며 갖게 되는 이점은 다음과 같습니다.

1. 블록이라는 단위로 쪼개서 저장을 하기 때문에 여러 개의 디스크(또는 장비)에 걸쳐 파일(데이터)을 저장 할 수 있습니다. 따라서 저장할 수 있는 파일(데이터) 하나의 크기가 단일 디스크의 용량보다 크더라도 저장이 가능합니다.
2. 블록으로 나눠서 저장을 하므로 내고장성과 가용성(Availability)를 위한 복제(Replication) 및 여러 장비에 분산 저장을 구현하는데 적합합니다. 일반적으로 3 Replication Factor로 각 블록에 대해 세개의 복제본을 생성하여 서로 다른 장비에 분산 저장하게 됩니다.



## 네임노드(Namenode)와 데이터노드(Datanode)

HDFS클러스터는 Master 역할을 가지고 있는 네임노드와 Worker 역할을 가지고 있는 데이터노드로 구성되어 있습니다. 

네임노드는 파일 시스템의 네임스페이스(Name Space)를 관리하며 모든 파일과 디렉터리에 대한 메타 데이터를 관리합니다. 또한 데이터노드에게 주기적으로 블록 위치 정보를 받아, 클러스터에 저장하고 있는 모든 블록이 어느 데이터 노드에 있는지 파악하고 있습니다. 이 메타 데이터는 FsImage와 EditsLog라는 파일로 네임 노드 로컬 디스크에 저장 됩니다.  



 데이터노드는 실질적으로 데이터를 저장하는 역할을 하며, 클라이언트나 네임노드의 요청에 의해 데이터를 저장 및 탐색합니다. 또한 하트비트(Heart Beat)를 통해 주기적으로 네임노드에게 각자의 상태 정보와 가지고 있는 블록의 위치 정보를 전달합니다. 데이터노드가 실질적으로 데이터를 소유하고 있지만 마스터 관계에 있는 네임노드가 손상될 경우 데이터노드가 가지고 있는 데이터는 읽거나 복구 할 수 없습니다.  

## 고가용성

앞서 언급했듯 마스터 역할을 하는 네임노드가 손상되었을 경우 해당 클러스터의 모든 데이터를 유실하게 됩니다. 이를 방지하기 위해 네임노드는 HA(High Availability)를 지원합니다. 이는 Active – Standby 구조의 한쌍의 네임노드로 구성 됩니다. Active 네임노드에 장애가 발생할 경우 Standby 네임노드가 바로 역할을 이어받아 클러스터의 장애를 예방 합니다. 이러한 고가용성을 구현하기 위해 QJM(Quorum Journal Manager)가 설계되었고 QJM을 통해 네임노드간에 최신 상태의 edits log가 공유됩니다.  



Standby 네임노드로 전환되는 작업은 Failover Controller에 의해 관리됩니다. 여러가지 방법으로 Failover Controller의 구현이 가능하지만 일반적으로 Zookeeper를 통해 구현됩니다. Failover Controller 프로세스는 네임노드로부터 상태정보를 전달하는 하트비트를 받아 각 네임노드의 상태를 파악하며, 장애가 발생시 정상 상태로 파악하고 있는 네임노드를 Active 네임노드로 변경합니다.  



## 마치며

여기까지 개념적인 부분들을 살펴보았습니다. 여기까지의 내용을 대부분 이해하셨다면 HDFS의 80% 이상의 개념은 파악하셨다고 봐도 무관하지 않을까 싶습니다. 좀 더 깊은 내용은 단순히 글로 읽으며 파악하시기 보다는 실제로 사용하고 운영해보면서 겪는 것이 가장 좋은 방법일 것이라고 생각합니다. 따라서 다음 포스팅에서는 실제로 HDFS를 어떻게 설치하고 구성할 수 있는지에 대해 포스팅하도록 하겠습니다. 여기까지 긴 글 읽어주셔서 감사합니다.  



## 참고

- [Apache Hadoop 공식 홈페이지](https://hadoop.apache.org/)
- OREILLY Hadoop The Definitive Guide
