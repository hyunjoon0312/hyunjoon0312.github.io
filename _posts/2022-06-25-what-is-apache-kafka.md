---
title:  "[Kafka #1] Apache Kafka 기본 개념 알아보기"
excerpt: "Apache Kafka에 대한 기본 개념에 대한 설명"
toc: true
toc_sticky: true
toc_label: "목차"

categories:
  - Kafka
tags:
  - Kafka

---
<p>&nbsp;</p>

최근 원영님의 아파치 카프카 애플리케이션 프로그래밍 강의를 듣기 시작하였습니다. 
그래서 이번 기회에 원영님의 강의를 들으며 제가 이해한 내용을 가지고 카프카에 대해 정리하는 강의 노트를 작성하려 합니다.
포스팅 중간 중간에 사용되는 그림은 원영님의 강의 자료에 있는 예제 그림을 사용하는 경우가 있으며, 사전에 원영님께 블로그 강의 노트에 사용해도 된다는 허락을 구하였습니다.
이번 첫번째 포스팅에서는 카프카의 기본적인 개념에 대해 작성하였습니다.

<p>&nbsp;</p>

# 1. 아파치 카프카(Apache Kafka)란?

링크드인(LinkedIn)은 시간이 지날수록 거대해지는 아키텍처로 인해서 소스 애플리케이션과 타깃 애플리케이션의 수가 점점 증가하였고, 파편화된 데이터 수집 및 분배 아키첵처를 운영하는데 큰 어려움을 겪고 있었습니다.
이를 해결하기 위해 다양한 상용 데이터 프레임워크와 오픈소스를 활요해보려 했지만 파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처를 만들기는 역부족이었고 결국 이를 해결하기 위한 자체 시스템을 개발하였습니다.
바로 이렇게 링크드인에서 내부 데이터 흐름을 개선하기 위해 개발한 것이 분산 메시지 시스템인 아파치 카프카(Apache Kafka) 입니다.

![HTML Element](https://drive.google.com/uc?export=view&id=1Ga4_b8BmPs3-aLaCxAWdmGRa1GNTvJvr)

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 특정한 곳에 여러 소스 애플리케이션으로 부터 데이터를 모아 처리할 수 있도록 중앙 집중화를 하였습니다.

![HTML Element](https://drive.google.com/uc?export=view&id=1N6AN6hbdCIW1OeqJ-RCrTvkwe89gLvJS)

카프카는 소스 애플리케이션과 타깃 애플리케이션이 서로 쌍을 이루어 소스 또는 타깃 애플리케이션이 문제를 일으킬 경우 전체 파이프 라인에 영향을 주었던 한계를 극복하였습니다. 
소스 애플리케이션은 타깃 애플리케이션과 독립되어 일단 카프카에 데이터를 저장하기만 하면 되고, 타깃 애플리케이션 역시 소스 애플리케이션과 무관하게 카프카에 저장되어 있는 데이터를 가져오기만 하도록 되었습니다.
이때 카프카에서 소스 애플리케이션을 `"프로듀서"`라고 부르며 데이터를 저장하는 곳은 `"브로커"`(토픽), 타깃 애플리케이션을 `"컨슈머"`라고 합니다.

프로듀서에서 메시지 하나를 보내면 다수의 파티션 중 로직에 맞는 하나의 파티션에 저장되며, 파티션에는 데이터가 `Queue 구조(FIFO)`로 저장 됩니다. 카프카 브로커에는 RDB의 테이블과 같은 개념인 `토픽`이 존재하고 토픽은 일반적으로 구분하고자 하는 데이터 종류 별로 생성합니다. 이 토픽 1개 이상의 파티션을 가질 수 있습니다. 그리고 컨슈머는 파티션에 있는 데이터를 가져오게 되며 이때 카프카의 특징 중 하나로 컨슈머가 데이터를 가져가더라도 파티션의 데이터는 삭제되지 않습니다. 컨슈머는 파티션에서 데이터를 어디까지 가져왔는지 기록하기 위해 `"커밋"`을 진행하게 됩니다.

<p>&nbsp;</p>

# 2. 카프카의 특징

## 2-1. 높은 처리량

카프카는 프로듀서가 브로커로 데이터를 보낼 때 데이터를 하나씩 보내는 것이 아니라 일정량의 데이터를 묶어서 한번에 전송하며 컨슈머가 브로커로부터 데이터를 가져갈 때도 일정량의 데이터를 묶어서 한번에 가져 갑니다.
이렇게 많은 양의 데이터를 묶음 단위로 전송하는 방식을 통하여 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소화함으로써 더 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그 데이터를 처리하는 데에 적합 합니다. 또한 파티션 개수와 파티션 개수만큼 컨슈머의 개수를 늘려서 동일한 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬처리하여 동일 시간당 데이터 처리량을 늘릴 수 있습니다.

![HTML Element](https://drive.google.com/uc?export=view&id=1bJX8--vJ54bNNFmQwQoAC3HtEDc6q9oG)

## 2-2. 확장성

데이터 파이프라인을 구성할 때 처음부터 데이터가 얼마나 유입될지 정확하게 예측하는 것은 매우 어렵습니다. 또한 평상시에 1,000건 정도의 데이터가 들어오다가도 예상치 못한 이벤트로 인해 몇 배의 데이터가 들어오는 경우도 발생합니다.
이러한 경우에 카프카는 유연한 확장성을 통해 안정적으로 데이터 파이프라인을 유지하도록 설계되어 있습니다. 즉, 데이터 유입이 적을 경우에는 카프카 클러스터의 브로커 개수를 최소한으로 운영하다가 데이터가 많아지는 경우 즉각적으로 브로커 개수를 늘려 스케일 아웃(scale-out) 방식으로 증가된 데이터 유입을 처리할 수 있습니다. 반대로 유입되는 데이터가 다시 적어지면 브로커 개수를 줄이는 스케일 인(scale-in) 방식도 가능합니다. 또한 이렇게 스케일 아웃, 스케일 인 작업을 클러스터의 재시작 없이 무중단으로 가능하다는 점이 큰 이점 입니다.

## 2-3. 영속성

영속성은 데이터를 생성한 프로그램이 종료되더라도 데이터가 사라지지 않는 특성을 뜻합니다. 이는 카프카가 전송받은 데이터를 인-메모리(in-memory) 형식으로 저장하지 않고 OS 레벨의 시스템에 파일로 저장하는 특징 때문에 가능합니다.
시스템에 파일로 저장하면 읽기/쓰기 속도가 느린 것이 일반적이지만 카프카는 페이지 캐시(page cache) 영역을 따로 생성 및 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식을 통하여 I/O 성능을 높였습니다. 이렇게 시스템 파일에 데이터를 저장하는 방식을 활용한 덕분에 브로커에 이슈가 생겨 갑작스럽게 종료되더라도 이슈 해결 후 해당 장비에서 브로커가 재실행되면 저장되어 있는 데이터 파일을 가지고 복구가 가능합니다.

## 2-4. 고가용성

일반적으로 카프카 클러스터는 3개 이상의 서버들로 구성 및 운영이 되기 때문에 이 중 일부서버에 장애가 발생하더라도 무중단으로 안정적이고 지속적으로 데이터를 처리할 수 있습니다. 클러스터로 이루어진 카프카는 하둡과 유사하게 프로듀서로부터 전송받은 데이터를 하나의 브로커에만 저장하는 것이 아니라 데이터 복제(replication)을 통해 하나의 브로커가 받은 데이터를 다른 장비의 브로커에 데이터를 복제하여 데이터 고가용성을 보장하게 됩니다. 

<p>&nbsp;</p>

# 3. 카프카의 구성

![HTML Element](https://drive.google.com/uc?export=view&id=1-zY6D0QgEhTluFoOwJXoNA52IsLMXObq)

## 3-1. 아파치 주키퍼(Apache Zookeeper)
카프카 클러스터를 구성하기 위해서는 카프카 외에도 아파치 주키퍼(Apache Zookeeper)가 필요합니다. 다만 카프카 3 버전부터는 주키퍼가 없이도 카프카를 실행하는 것이 가능하지만 아직까지는 완벽하게 주키퍼가 하던 역할을 대체하고 있지 못하기 때문에 상용으로 사용되는 아키텍처에서는 주키퍼와 함께 사용 되고 있습니다. 카프카에서 주키퍼가 하는 역할은 분산 애플리케이션의 안정적인 서비스를 할 수 있도록 하는 역할로 여러 카프카 브로커 중 컨트롤러를 선정하고 브로커의 상태 정보를 기록한 메타 데이터를 관리하며 토픽의 파티션 수 등의 토픽 메타데이터를 기록 합니다. 또한 카프카의 토픽에 대해 읽기/쓰기 권한을 제어하는 ACL에 대한 정보도 주키퍼가 저장하고 있습니다.

## 3-2.브로커의 역할

### 1) 컨트롤러
앞서 주키퍼가 여러 브로커 중 한대를 컨트롤러로 선정한다고 언급하였습니다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배하는 역할을 합니다. 또한 이 컨트롤러 역할을 하는 브로커에 장애가 생길 경우에는 다른 브로커에게 컨트롤러 역할이 재선정 됩니다.

### 2) 데이터 삭제
카프카의 특징 중 하나로 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않으며 프로듀서나 컨슈머는 데이터 삭제 요청을 할 수 없습니다. 카프카에서 브로커만이 데이터를 삭제할 수 있으며, 이때 데이터 삭제 역시 특정 데이터를 하나하나 선별하여 삭제하는 것은 불가능하고 반드시 `로그 세그먼트(log segment)`라고 부르는 파일 단위로 삭제가 이루어 집니다. 따라서 카프카에서 데이터 삭제의 최소 단위는 한 로그 세그먼트에 포함되어 있는 다수의 데이터 입니다.

### 3) 컨슈머 오프셋 저장
컨슈머는 토픽의 특정 파티션에서 데이터를 가져가면 어느 레코드까지 데이터를 가져갔는지 저장하기 위해 오프셋을 `커밋(commit)`하게 됩니다. 이때 커밋한 오프셋은 `__consumer_offsets`라는 토픽에 저장되고 컨슈머는 여기에 저장된 오프셋을 토대로 파티션의 다음 레코드를 가져가게 됩니다.

### 4) 그룹 코디네이터
브로커는 그룹 코디네이터 역할도 수행하는데 컨슈머 그룹의 상태를 체크하고 토픽에 가지고 있는 파티션을 컨슈머와 매칭되도록 분배하는 역할을 합니다. 어떤 컨슈머가 장애로 인해 컨슈머 그룹에서 빠지게 되면 컨슈머가 사라진 파티션을 정상 동작하는 다른 컨슈머로 할당하여 중단 없이 데이터가 처리되도록 해줍니다. 이와 같이 파티션을 컨슈머에 재할당하는 작업을 `리밸런스(rebalance)`라고 부릅니다.

### 5) 데이터 저장
카프카는 처음 실행할 때 `~/config/server.properties` 환경설정 파일의 `log.dir` 옵션에 정의한 디렉터리에 데이터를 저장합니다. 이때 데이터가 저장되는 디렉터리명은 토픽 이름과 파티션 번호의 조합으로 생성됩니다. 예를 들어 디렉터리 명이 `hello.kafka-0`이라면 hello.kafka 토픽의 0번 파티션에 존재하는 데이터를 저장하는 디렉터리 입니다. 해당 디렉터리에는 레코드의 오프셋을 인덱싱한 정보를 다음 `index` 파일, 레코드에 포함된 timestamp 값을 기준으로 인덱싱한 `timeindex`파일, 실제 데이터 파일인 `log` 파일, 파티션의 리더에 대한 기록인 `leader-epoch-checkpoint` 파일을 포함하고 있습니다.

![HTML Element](https://drive.google.com/uc?export=view&id=1oHJK0FKhaA6STh6n_IRKTpEylqCjo01E)

## 3-3. 로그와 세그먼트

카프카는 데이터를 하나 하나 보내는 것이 아닌 특정 묶음으로 모아 배치로 보낸다고 이야기 했었습니다. 이때 이 묶음을 세그먼트라고 부르며, 세그먼트의 크기는 `log.segment.bytes` 설정 값과 `log.roll.ms` 설정 값에 따라 달라집니다.

- log.segment.bytes : 바이트 단위로 최대 세그먼트 크기를 지정(defaut : 1GB)
- log.roll.ms(hours) : 하나의 세그먼트가 신규 생성된 후 다음 세그먼트로 넘어가는 시간 주기(defualt : 7d)

세그먼트는 세그먼트 최대 크기만큼 데이터가 들어오거나 최대 크기만큼 데이터가 들어오지 않았으나 주기가 지나게 될 경우 다음 세그먼트를 새로 생성하게 됩니다.

### 1) 액티브 세그먼트(Active Segment)
액티브 세그먼트는 세그먼트 크기 또는 세그먼트 주기가 지나지 않아 현재 쓰기가 진행 중인 세그먼트를 이야기 합니다. 액티브 세그먼트는 브로커의 삭제 조건(retention 옵션)이 되더라도 삭제 대상에 포함되지 않습니다.

### 2) 세그먼트의 삭제
카프카의 세그먼트는 브로커에 설정된 retention 주기에 따라 삭제가 일어납니다. 이때 세그먼트를 삭제하기 위해서는 `cleanup.policy` 설정 값이 `delete`로 되어 있어야하며, 대상은 액티브 세그먼트를 제외한 일반 세그먼트 입니다. 
다음과 같이 시간과 파티션당 적재된 로그의 크기로 삭제 주기를 지정할 수 있습니다.

- retention.ms(minutes, hours) : 세그먼트 최대 보유 기간(defualt : 7d)
- retention.bytes : 파티션당 최대 적재 사이즈(default : -1 // 지정하지 않음)
- log.retention.check.interbal.ms : 삭제할 세그먼트가 있는지 확인하는 간격(defualt : 5m)

### 3) 세그먼트의 압축
세그먼트의 완전한 삭제가 아닌 압축을 통하여 데이터 용량 관리를 하고 싶다면 `cleanup.policy` 설정 값을 `compact`로 설정하면 됩니다.
여기서 압축은 흔히 생각하는 zip과 같은 압축(compression)과는 다른 개념으로 레코드 별로 가지고 있는 메시지 키(Key) 값에 따라 최신 레코드를 제외한 과거의 레코드를 삭제하는 정책을 뜻합니다. 따라서 `delete`는 대상이 되는 모든 레코드를 삭제하는 반면 `compact`는 메시지 키가 중복되는 일부 과거 레코드만 삭제되게 됩니다. 이때 압축이 완료되어 중복 메시지 키가 없는 레코드들을 `클린(clean) 레코드` 라고 부르며, 압축이 수행되기 전에 중복된 메시지 키가 있는 레코드들을 `더티(dirty) 레코드` 라고 부릅니다.

![HTML Element](https://drive.google.com/uc?export=view&id=1Ap5U1h64KZOtWy1487mGtdtdK_j3ra8P)

압축 시작 시점은 `min.cleanable.dirty.ratio` 값에 따라 달라 집니다. 해당 옵션은 액티브 세그먼트를 제외한 일반 세그먼트에 남아 있는 클린 레코드와 더티 레코드 수의 비율(더티 레코드/클린 레코드)을 의미 합니다. 예를 들어 0.5로 설정할 경우 더티 레코드의 수가 클린 레코드 수의 1/2만큼 생길 경우 압축을 시작하며, 0.9일 경우 더티 레코드의 수가 클린 레코드 수에 비해 90% 정도 생길 경우 압축을 시작 합니다. 이와 같이 큰 비율을 설정을 하면 한번 압축을 진행할 때 많은 수의 레코드가 줄어들게 되어 압축 효율은 좋으나 0.9가 될 때까지 압축을 진행하지 않기 때문에 용량 사용 효율은 좋지 않습니다. 다만 0.1과 같이 너무 작은 수로 설정하게 되면 압축이 자주 발생하여 브로커에 부담을 줄 수 있습니다.

<p>&nbsp;</p>

# 4. 마치며
이번 포스팅에서는 정말 카프카의 기본개념인 카프카는 무엇이고 카프카는 어떻게 구성되어 있는지에 대해 알아보았습니다. 앞으로 원영님의 카프카 강의를 들으며 조금씩 카프카에 대해 좀 더 자세히 공부해보고 포스팅하는 시간을 갖도록 하겠습니다.
제가 정리한 내용 중 잘못 된 내용이나 부족한 내용이 있으면, 가감 없이 댓글로 코멘트 부탁드리겠습니다.
